{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T18:46:24.930751Z",
     "start_time": "2019-05-29T18:46:23.134697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maayanlab/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from ggplot import *\n",
    "\n",
    "\n",
    "from ruffus import *\n",
    "import sys, os, h5py, random, tempfile, scipy, time,copy\n",
    "import cmapPy.pandasGEXpress.parse_gctx as parse_gctx\n",
    "import cmapPy.pandasGEXpress.parse_gct as parse_gct\n",
    "import pipeline_support as PS\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from collections import Counter\n",
    "#from tensorflow_examples.models.pix2pix import pix2pix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import clear_output\n",
    "from tensorflow_gan.python.losses import losses_impl\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampling = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHS4_filename = \"../data/ARCHS4/human_matrix_v9.h5\"\n",
    "l1000_all_gene_list = \"../data/L1000/all_gene_list.txt\"\n",
    "l1000_landmark_gene_list = \"../data/L1000/landmark_gene_list.txt\"\n",
    "\n",
    "archs4_all_gene_list = \"../data/ARCHS4/all_gene_list.txt\"\n",
    "archs4_high_count_gene_list = \"../data/ARCHS4/high_count_gene_list.txt\" # from 4_normalize_ARCHS4_full ~\n",
    "\n",
    "gtex_l1000_all_gene_list = \"../data/GTEx/l1000_all_gene_list.txt\"\n",
    "gtex_l1000_landmark_gene_list = \"../data/GTEx/l1000_landmark_gene_list.txt\"\n",
    "\n",
    "gtex_rnaseq_all_gene_list = \"../data/GTEx/rnaseq_all_gene_list.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHS4_filtered_sample_output_filename = \"../data/processed/ARCHS4/filtered_sample_list.txt\"\n",
    "ARCHS4_filtered_overlap_landmark_output_filename = \"../data/processed/ARCHS4/human_matrix_v9_filtered_n{}x{}.f\" # n_samplingx967"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get overlap landmark genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(l1000_landmark_gene_list, \"r\") as f:\n",
    "    l1000_landmark_gene = [x.strip() for x in f.readlines()]\n",
    "with open(archs4_all_gene_list, \"r\") as f:\n",
    "    archs4_all_gene = [x.strip() for x in f.readlines()]\n",
    "with open(gtex_l1000_landmark_gene_list, \"r\") as f:\n",
    "    gtex_l1000_landmark_gene = [x.strip() for x in f.readlines()]\n",
    "with open(gtex_rnaseq_all_gene_list, \"r\") as f:\n",
    "    gtex_rnaseq_all_gene = [x.strip() for x in f.readlines()]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_landmark_genes = list(set(l1000_landmark_gene).intersection(archs4_all_gene).intersection(gtex_l1000_landmark_gene).intersection(gtex_rnaseq_all_gene))\n",
    "overlap_rnaseq_genes = list(set(archs4_all_gene).intersection(gtex_rnaseq_all_gene)) # common genes in ARCHS4 and GTEx RNA-seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial: Load ARCHS4 RNA-seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing code from https://github.com/MaayanLab/L1k2RNA-seq-2.0/blob/cb5eaa3a447b502e32db6c1aae84eaa94d0ce0f4/pipeline/pipeline.py#L43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RNA-seq data.....\n"
     ]
    }
   ],
   "source": [
    "# Import ARCHS4 RNA-seq samples \n",
    "print('Processing RNA-seq data.....')\n",
    "h5 = h5py.File(ARCHS4_filename, 'r')\n",
    "data_file = h5['data'] \n",
    "expression = data_file['expression']\n",
    "genes = [x for x in h5['meta']['genes']['genes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find samples with > 1 million reads\n",
    "idx_read_sums_keep = [i for i, x in enumerate(h5['meta']['samples']['readstotal']) if x > 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35238, 307268)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate # samples in each study\n",
    "studies_count_dict = Counter(h5['meta']['samples']['series_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(archs4_high_count_gene_list, \"r\") as f:\n",
    "    high_count_gene_list = [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark gene index\n",
    "archs4_landmark_gene_index = [i for i, x in enumerate(genes) if x in high_count_gene_list]\n",
    "archs4_landmark_gene_names = [x for i, x in enumerate(genes) if x in high_count_gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-782c73b12eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# filter landmake genes and covert array to pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlandmark_gene_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marchs4_landmark_gene_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlandmark_gene_expression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchs4_landmark_gene_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# filter landmake genes and covert array to pandas dataframe \n",
    "landmark_gene_expression = pd.DataFrame(expression[archs4_landmark_gene_index])\n",
    "landmark_gene_expression.index = archs4_landmark_gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landmark_gene_expression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n"
     ]
    }
   ],
   "source": [
    "# Remove single cell samples that are < 1 million reads and from studies with > 200 samples\n",
    "samples = list()\n",
    "samples_index = list()\n",
    "filtered_expression = list()\n",
    "i = 0\n",
    "for sample_id, series_id in zip(h5['meta']['samples']['geo_accession'], h5['meta']['samples']['series_id']):\n",
    "    if i in idx_read_sums_keep and studies_count_dict[series_id] <= 200:\n",
    "        samples.append(sample_id)\n",
    "        samples_index.append(i)\n",
    "    if i % 10000 == 0:\n",
    "        print(i)    \n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out samples \n",
    "filtered_landmark_gene_expression = landmark_gene_expression.iloc[:, samples_index]\n",
    "filtered_landmark_gene_expression.columns = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/ARCHS4/human_matrix_v9_filtered_n967x154575.f\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "filtered_landmark_gene_expression.reset_index().to_feather(ARCHS4_filtered_landmark_output_filename.format(filtered_landmark_gene_expression.shape[0], filtered_landmark_gene_expression.shape[1]))\n",
    "print(ARCHS4_filtered_landmark_output_filename.format(filtered_landmark_gene_expression.shape[0], filtered_landmark_gene_expression.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample ids\n",
    "with open(ARCHS4_filtered_sample_output_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join(samples))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
