{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for Processing ARCHS4 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T18:46:24.930751Z",
     "start_time": "2019-05-29T18:46:23.134697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "import random\n",
    "\n",
    "import sys, h5py, time\n",
    "import cmapPy.pandasGEXpress.parse_gctx as parse_gctx\n",
    "import cmapPy.pandasGEXpress.parse_gct as parse_gct\n",
    "\n",
    "from scipy import stats\n",
    "from numpy.random import seed\n",
    "\n",
    "import scipy.stats as ss\n",
    "import warnings\n",
    "import numpy as np\n",
    "from maayanlab_bioinformatics.normalization import quantile_normalize\n",
    "\n",
    "\n",
    "randomState = 123\n",
    "seed(randomState)\n",
    "random.seed(randomState)"
   ]
  },
  {
   "source": [
    "## Initialize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampling = 150000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHS4_filename = \"../data/ARCHS4/human_matrix_v9.h5\"\n",
    "overlap_landmark_gene_list = \"../data/processed/overlap_landmark_gene_file.txt\"\n",
    "overlap_rnaseq_gene_list = \"../data/processed/overlap_rnaseq_gene_file.txt\"\n",
    "archs4_high_count_gene_list = \"../data/ARCHS4/high_count_gene_list.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHS4_filtered_sample_output_filename = \"../data/processed/ARCHS4/filtered_sample_list.txt\"\n",
    "ARCHS4_filtered_output_filename = \"../data/processed/ARCHS4/human_matrix_v9_filtered_n{}x{}.f\" # n_samplingx25312\n",
    "ARCHS4_filtered_output_filename_normalized = \"../data/processed/ARCHS4/human_matrix_v9_filtered_n{}x{}_v2.f\" # n_samplingx25312\n",
    "ARCHS4_filtered_output_filename_normalized_overlap_landmark = \"../data/processed/ARCHS4/human_matrix_v9_filtered_n{}x{}_v2.f\" # n_samplingx962\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feather(df, filename):\n",
    "    df.reset_index().to_feather(filename)\n",
    "    print(\"Saved!\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load landmark/RNA-seq genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(overlap_landmark_gene_list, \"r\") as f:\n",
    "    landmark_gene = [x.strip() for x in f.readlines()]\n",
    "with open(overlap_rnaseq_gene_list, \"r\") as f:\n",
    "    overlap_rnaseq_genes = [x.strip() for x in f.readlines()]    \n",
    "with open(archs4_high_count_gene_list, \"r\") as f:\n",
    "    high_count_gene_list = [x.strip() for x in f.readlines()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ARCHS4 RNA-seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing code from https://github.com/MaayanLab/L1k2RNA-seq-2.0/blob/cb5eaa3a447b502e32db6c1aae84eaa94d0ce0f4/pipeline/pipeline.py#L43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import ARCHS4 RNA-seq samples \n",
    "print('Processing RNA-seq data.....')\n",
    "h5 = h5py.File(ARCHS4_filename, 'r')\n",
    "data_file = h5['data'] \n",
    "expression = data_file['expression']\n",
    "genes = [x for x in h5['meta']['genes']['genes']]\n",
    "sample_geo_list = list(h5['meta']['samples']['geo_accession'])\n",
    "sample_series_id = list(h5['meta']['samples']['series_id'])\n",
    "reads_total = list(h5['meta']['samples']['readstotal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high count gene index\n",
    "archs4_high_count_gene_index = [i for i, x in enumerate(genes) if x in high_count_gene_list]\n",
    "archs4_high_count_gene_names = [x for i, x in enumerate(genes) if x in high_count_gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneate metadata\n",
    "metadf = pd.DataFrame([sample_geo_list, sample_series_id, reads_total]).T\n",
    "metadf.columns = [\"geo_accession\", \"series_id\", \"readstotal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series less than 200 samples\n",
    "metadf_count = metadf.groupby(\"series_id\").count()\n",
    "series_ids_with_less_200samples = metadf_count[metadf_count[\"geo_accession\"] < 200].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find samples with 1M reads from studies less than 200 samples\n",
    "filtered_metadf = metadf[(metadf[\"readstotal\"] > 1000000) & (metadf[\"series_id\"].isin(series_ids_with_less_200samples))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling\n",
    "sampled_ids = random.sample(filtered_metadf[\"geo_accession\"].tolist(), n_sampling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_metadf = filtered_metadf[filtered_metadf[\"geo_accession\"].isin(sampled_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "sampled_expression_gene = list()\n",
    "strt_time = time.time()\n",
    "for i in range(int(n_sampling/chunk_size)):\n",
    "    \n",
    "    tmp_metadf = sampled_metadf.iloc[i*chunk_size:(i+1)*chunk_size, :]\n",
    "    \n",
    "    sampled_index_i = tmp_metadf.index.tolist()\n",
    "    expression_i = expression[:, sorted(sampled_index_i)]\n",
    "    expression_i_df = pd.DataFrame(expression_i)\n",
    "    expression_i_df.columns = tmp_metadf[\"geo_accession\"].tolist()\n",
    "    expression_i_df.index = genes    \n",
    "    expression_i_df = expression_i_df.loc[high_count_gene_list, :]\n",
    "    sampled_expression_gene.append(expression_i_df)\n",
    "\n",
    "    print(i, time.time()-strt_time)\n",
    "    strt_time = time.time()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df = pd.concat(sampled_expression_gene, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df = expression_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "save_feather(expression_df, ARCHS4_filtered_output_filename.format(expression_df.shape[0], expression_df.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample ids\n",
    "with open(ARCHS4_filtered_sample_output_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join(expression_df.index.tolist()))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPM(data):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        data = (data/data.sum())*10**6\n",
    "        data = data.fillna(0)\n",
    "        \n",
    "    return data\n",
    "def logCPM(data):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        data = (data/data.sum())*10**6\n",
    "        data = data.fillna(0)\n",
    "        data = np.log10(data+1)\n",
    "\n",
    "    # Return\n",
    "    return data\n",
    "def log(data):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        data = data.fillna(0)\n",
    "        data = np.log10(data+1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def qnormalization(data):\n",
    "\n",
    "    X_quantile_norm = quantile_normalize(data)\n",
    "    return X_quantile_norm  \n",
    "\n",
    "def normalization(data, logCPM_normalization=False, CPM_normalization=False, log_normalization=False, z_normalization=False, q_normalization=False):\n",
    "    if logCPM_normalization == True:  \n",
    "        data = logCPM(data)\n",
    "    if CPM_normalization == True:\n",
    "        data = CPM(data)\n",
    "    if log_normalization == True:   \n",
    "        data = log(data)\n",
    "        \n",
    "    if q_normalization == True:\n",
    "        data = qnormalization(data)\n",
    "        \n",
    "    \n",
    "    if z_normalization == True: \n",
    "        data = data.T.apply(ss.zscore, axis=0).T.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary : load expression_df\n",
    "expression_df = pd.read_feather(ARCHS4_filtered_output_filename.format(150000, 23614))\n",
    "first_col = expression_df.columns.tolist()[0]\n",
    "expression_df = expression_df.set_index(first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df = expression_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ARCHS4 = normalization(expression_df.T, logCPM_normalization=True, q_normalization=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ARCHS4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_feather(normalized_ARCHS4, ARCHS4_filtered_output_filename_normalized.format(normalized_ARCHS4.shape[0], normalized_ARCHS4.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Landmark genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ARCHS4_overlap_landmark = normalized_ARCHS4.loc[:, landmark_gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ARCHS4_overlap_landmark = normalized_ARCHS4_overlap_landmark.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ARCHS4_overlap_landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_feather(normalized_ARCHS4_overlap_landmark, ARCHS4_filtered_output_filename_normalized_overlap_landmark.format(normalized_ARCHS4_overlap_landmark.shape[0], normalized_ARCHS4_overlap_landmark.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}