{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('python37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "385bb8b00568b82143462c5773842a3f7e8f0255e7b9eecbe3525094c674661a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# L1000 to RNA-seq conversion pipeline - Training, Predicting & Evaluating"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This is an L1000 to RNA-seq conversion pipeline. The pipeline takes 978-dimensional Level3 L1000 profiles as input and returns 25,312-dimensional RNA-seq like profiles. A cycleGAN model in step 1 converts gene expression values in L1000 to those in RNA-seq only for landmark genes. Then, step 2 takes the output profiles of step 1 and extrapolates the profiles to the 25,312 full genome profiles.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from numpy.random import seed\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "source": [
    "Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_exp_index = 30\n",
    "step2_exp_index = 30\n",
    "num_samples = 50000\n",
    "\n",
    "step1_y_true_filename = \"y_true_L1000_MCF7.txt\"\n",
    "step1_y_pred_filename = \"y_pred_L1000_MCF7.txt\"\n",
    "step2_y_true_filename = \"y_true_ARCHS4_MCF7.txt\"\n",
    "step2_y_pred_filename = \"y_pred_ARCHS4_MCF7.txt\"\n",
    "eval_dataset_nameA = \"L1000_MCF7\"\n",
    "eval_dataset_nameB = \"ARCHS4_MCF7_landmark\"\n",
    "\n",
    "# step1_y_true_filename = \"y_true_L1000_GTEx.txt\"\n",
    "# step1_y_pred_filename = \"y_pred_L1000_GTEx.txt\"\n",
    "# step2_y_true_filename = \"y_true_ARCHS4_GTEx.txt\"\n",
    "# step2_y_pred_filename = \"y_pred_ARCHS4_GTEx.txt\"\n",
    "# eval_dataset_nameA = \"GTEx_L1000\"\n",
    "# eval_dataset_nameB = \"GTEx_RNAseq_landmark\"\n",
    "# eval_output_dataset_name = \"GTEx_RNAseq\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Training: Step 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python functions/delete.py --exp_index $step1_exp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjjeon\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.24 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mastral-frog-45\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/mjjeon/L1000toRNAseq_step1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/mjjeon/L1000toRNAseq_step1/runs/37idc7mr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/maayanlab/Projects/minji/cycleGAN_gene_expression/scripts/wandb/run-20210331_174655-37idc7mr\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Namespace(b1=0.9, b2=0.999, batch_size=100, benchmark_evaluation=True, cell_line=None, checkpoint_interval=10, dataset_nameA='L1000', dataset_nameB='ARCHS4', decay_epoch=50, epoch_resume=0, eval_dataset_nameA='L1000_MCF7', eval_dataset_nameB='ARCHS4_MCF7_landmark', evaluation=False, exp_index=30, gamma=0.1, hidden_dimA=512, hidden_dimB=512, input_dimA=962, input_dimB=962, ispredicting=False, lambda_cyc=10.0, lambda_id=0.0, load_model_index=100, lr=0.0002, n_cpu=8, n_epochs=100, n_residual_blocks=1, num_samples=50000, output_dimA=128, output_dimB=128, prediction_folder='../output/30/prediction/', sample_interval=100, shuffle=False, weight_decay=1e-05, y_pred_output_filename=None, y_true_output_filename=None)\n",
      "Cuda available True\n",
      "../data/processed/L1000/L1000_filtered_GSE92742_Broad_LINCS_Level3_INF_mlr12k_n50000x962.f\n",
      "../data/processed/ARCHS4/human_matrix_v9_filtered_n50000x962_v2.f\n",
      "                                                AARS  ...       ZW10\n",
      "cid                                                   ...           \n",
      "CPC012_HT29_6H_X5_B5_DUO52HI53LO:D04        9.209949  ...  11.113700\n",
      "KDB009_HCC515_96H_X2_F1B5_DUO52HI53LO:G16  10.403400  ...   8.621300\n",
      "ERG012_VCAP_24H_X1.A2_B7_DUO52HI53LO:M15    9.008100  ...   9.637700\n",
      "KDB003_PC3_144H_X1_B1_DUO52HI53LO:H08       9.590100  ...   9.972300\n",
      "KDB010_VCAP_120H_X3_F1B4_DUO52HI53LO:H09    9.603950  ...   8.768700\n",
      "...                                              ...  ...        ...\n",
      "RAD001_MCF7_24H_X3_F1B5_DUO52HI53LO:E11    11.564250  ...   9.722651\n",
      "CYT001_A375_2H_X2_B7_DUO52HI53LO:B07       10.309200  ...   9.138300\n",
      "CVD001_PHH_24H_X3_F1B3_DUO52HI53LO:O21     10.088100  ...  10.482700\n",
      "KDD002_HA1E_96H_X1_F2B5_DUO52HI53LO:J04    10.313000  ...  12.795300\n",
      "KDD003_MCF7_96H_X3_B4_DUO52HI53LO:C13      12.122601  ...   8.060500\n",
      "\n",
      "[50000 rows x 962 columns]\n",
      "                    AARS         ABCB6  ...        ZNF589          ZW10\n",
      "index                                   ...                            \n",
      "GSM741172   2.163890e+00  1.856143e+00  ...  9.343677e-01  1.165529e+00\n",
      "GSM678413   1.534396e+00 -2.242457e-08  ...  1.120599e+00  4.442713e-01\n",
      "GSM1193921  2.059584e+00  8.702762e-01  ...  9.255946e-01  1.640780e+00\n",
      "GSM1241385  2.508563e+00  1.441441e+00  ...  9.468740e-01  7.268926e-01\n",
      "GSM1185605  1.554498e+00  8.349250e-01  ...  1.366783e+00  1.023698e+00\n",
      "...                  ...           ...  ...           ...           ...\n",
      "GSM4799129  2.136709e+00  1.336542e+00  ...  1.405141e+00  1.044936e+00\n",
      "GSM4799131 -2.242457e-08 -2.242457e-08  ... -2.242457e-08 -2.242457e-08\n",
      "GSM4799132  1.833854e+00  1.897191e+00  ...  1.358358e+00  1.219700e+00\n",
      "GSM4799134  1.738674e+00  1.203357e+00  ...  1.579855e+00  1.432489e+00\n",
      "GSM4799135  4.658679e-01  1.943515e-01  ...  1.548760e+00  1.251813e+00\n",
      "\n",
      "[50000 rows x 962 columns]\n",
      "(50000, 962)\n",
      "[Epoch 2/100] [Batch 335/500] [D loss: 0.211470] [G loss: 4.708982, adv: 0.447037, cycle: 0.426195, identity: 478.928436] ETA: 0:11:36.406797^C\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"functions/cyclegan_transcript.py\", line 726, in <module>\n",
      "    main()\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"functions/cyclegan_transcript.py\", line 377, in main\n",
      "    fake_B = G_AB(real_A)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/maayanlab/Projects/minji/cycleGAN_gene_expression/scripts/functions/models_transcript.py\", line 74, in forward\n",
      "    return self.model(x)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/maayanlab/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 21882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python functions/cyclegan_transcript.py --dataset_nameA \"L1000\" --dataset_nameB \"ARCHS4\" --n_epochs 100 --decay_epoch 50 --input_dimA 962 --hidden_dimA 512 --output_dimA 128 --input_dimB 962 --hidden_dimB 512 --output_dimB 128 --num_samples $num_samples --batch_size 100 --exp_index $step1_exp_index --prediction_folder \"../output/\"$step1_exp_index\"/prediction/\" --lambda_id 0.0 --benchmark_evaluation --eval_dataset_nameA $eval_dataset_nameA --eval_dataset_nameB $eval_dataset_nameB "
   ]
  },
  {
   "source": [
    "## Training: Step 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python functions/delete.py --exp_index $step2_exp_index --step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjjeon\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.24 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclassic-oath-84\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/mjjeon/L1000toRNAseq_step2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/mjjeon/L1000toRNAseq_step2/runs/1kdfocn6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/maayanlab/Projects/minji/cycleGAN_gene_expression/scripts/wandb/run-20210331_180215-1kdfocn6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Namespace(b1=0.9, b2=0.999, batch_size=100, cell_line=None, checkpoint_interval=10, decay_epoch=10, early_stopping=True, early_stopping_epoch=3, early_stopping_tol=0.0001, epoch_resume=0, eval_exp_index=8, eval_input_dataset_name='GTEx', eval_output_dataset_name='GTEx', evaluation=False, exp_index=30, gamma=0.5, hidden_dim=[2048, 4096, 8192], input_dataset_name='ARCHS4_50000_input', input_dim=962, ispredicting=False, lr=0.0002, n_cpu=8, n_epochs=100, num_samples=50000, output_dataset_name='ARCHS4_50000_output', output_dim=23614, output_gene_list='prediction_gene_list.txt', prediction_folder='../output_step2/30/prediction', sample_interval=100, shuffle=False, test_ratio=0.01, valid_ratio=0.01, y_pred_output_filename='y_pred.txt', y_true_output_filename='y_true.txt')\n",
      "Cuda available True\n",
      "../data/processed/ARCHS4/human_matrix_v9_filtered_n50000x962_v2.f\n",
      "(50000, 962)\n",
      "                    AARS         ABCB6  ...        ZNF589          ZW10\n",
      "index                                   ...                            \n",
      "GSM741172   2.163890e+00  1.856143e+00  ...  9.343677e-01  1.165529e+00\n",
      "GSM678413   1.534396e+00 -2.242457e-08  ...  1.120599e+00  4.442713e-01\n",
      "GSM1193921  2.059584e+00  8.702762e-01  ...  9.255946e-01  1.640780e+00\n",
      "GSM1241385  2.508563e+00  1.441441e+00  ...  9.468740e-01  7.268926e-01\n",
      "GSM1185605  1.554498e+00  8.349250e-01  ...  1.366783e+00  1.023698e+00\n",
      "...                  ...           ...  ...           ...           ...\n",
      "GSM4799129  2.136709e+00  1.336542e+00  ...  1.405141e+00  1.044936e+00\n",
      "GSM4799131 -2.242457e-08 -2.242457e-08  ... -2.242457e-08 -2.242457e-08\n",
      "GSM4799132  1.833854e+00  1.897191e+00  ...  1.358358e+00  1.219700e+00\n",
      "GSM4799134  1.738674e+00  1.203357e+00  ...  1.579855e+00  1.432489e+00\n",
      "GSM4799135  4.658679e-01  1.943515e-01  ...  1.548760e+00  1.251813e+00\n",
      "\n",
      "[50000 rows x 962 columns]\n",
      "../data/processed/ARCHS4/human_matrix_v9_filtered_n50000x23614_v2.f\n",
      "(50000, 23614)\n",
      "                A1BG          A1CF           A2M  ...       ZYX     ZZEF1      ZZZ3\n",
      "index                                             ...                              \n",
      "GSM741172   0.473907  3.705680e-01  2.184534e+00  ...  2.333243  2.006420  1.683348\n",
      "GSM678413   1.963902  3.982063e-01 -2.242457e-08  ...  1.830902  1.372154  1.368210\n",
      "GSM1193921  0.604064  1.055822e-01 -2.242457e-08  ...  2.082802  1.810972  1.826033\n",
      "GSM1241385  0.738513  5.518565e-02  2.193771e+00  ...  1.945563  1.683348  1.278944\n",
      "GSM1185605  0.938222  9.937055e-02  4.628249e-01  ...  2.347519  2.087565  1.566417\n",
      "...              ...           ...           ...  ...       ...       ...       ...\n",
      "GSM4799129  1.234056  1.985379e-01  2.778105e+00  ...  1.321659  1.218743  2.009551\n",
      "GSM4799131  1.182537 -2.242457e-08  2.617372e+00  ...  1.865611  1.411456  1.845311\n",
      "GSM4799132  1.332885  9.688548e-02  1.160650e+00  ...  1.427796  1.724931  1.521006\n",
      "GSM4799134  0.944716  5.810333e-01  2.659075e+00  ...  1.513049  1.234312  1.171328\n",
      "GSM4799135  1.727977  1.414330e+00  2.653870e+00  ...  0.927429  1.597058  1.905254\n",
      "\n",
      "[50000 rows x 23614 columns]\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 1/100] Train loss: 0.108315\n",
      "[Epoch 1/100] valid loss: 0.073671\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.45977553931821963\t0.073671214\t0.937363982228748\t0.9078938521435317\t0.07367121577262878\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 1/100] test loss: 0.075827\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.4475555074019822\t0.075827375\t0.9356742264027523\t0.9033966358047176\t0.07582737952470779\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 2/100] Train loss: 0.067350\n",
      "[Epoch 2/100] valid loss: 0.061488\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5340018316681321\t0.06148838\t0.947545997122812\t0.9169498736592402\t0.061488384008407594\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 2/100] test loss: 0.062640\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5240003238529516\t0.06263979\t0.9466801414751829\t0.9136184047485957\t0.06263979375362397\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 3/100] Train loss: 0.059734\n",
      "[Epoch 3/100] valid loss: 0.056731\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5643729251258145\t0.05673082\t0.9519326227881705\t0.9209098439328229\t0.05673082247376442\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 3/100] test loss: 0.057925\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5527032015787532\t0.057925243\t0.9509322445174396\t0.9178346690644029\t0.05792523995041847\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 4/100] Train loss: 0.055539\n",
      "[Epoch 4/100] valid loss: 0.053666\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5823727909382267\t0.0536656\t0.9545510522282078\t0.9230789103793149\t0.05366560220718384\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 4/100] test loss: 0.055277\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5667802568217902\t0.055277225\t0.9533107238481382\t0.919726899790435\t0.055277228355407715\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 5/100] Train loss: 0.052584\n",
      "[Epoch 5/100] valid loss: 0.050563\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6022896873769669\t0.050562713\t0.9569368275102642\t0.9251824307344976\t0.05056271180510521\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 5/100] test loss: 0.052131\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.5862785592690378\t0.052131478\t0.9556380659418702\t0.9216976144022058\t0.05213148295879364\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 6/100] Train loss: 0.050309\n",
      "[Epoch 6/100] valid loss: 0.048655\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6141669621705552\t0.04865525\t0.9586388509643342\t0.9267283893026993\t0.04865524545311928\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 6/100] test loss: 0.050520\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.595518988801863\t0.050519496\t0.9571164699595776\t0.922855608104632\t0.05051950067281723\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 7/100] Train loss: 0.048242\n",
      "[Epoch 7/100] valid loss: 0.047007\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6253206364395612\t0.047006883\t0.9600976363786222\t0.9281194085556789\t0.04700688123703003\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 7/100] test loss: 0.049152\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6046043032351981\t0.049151614\t0.958346837970908\t0.9242199328892273\t0.049151618778705594\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 8/100] Train loss: 0.047349\n",
      "[Epoch 8/100] valid loss: 0.045842\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6335069123541707\t0.045841932\t0.9612822307714334\t0.929122308750186\t0.04584193006157875\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 8/100] test loss: 0.048058\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6123624257790484\t0.048057776\t0.9593918017880464\t0.9248616571012472\t0.048057776689529416\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 9/100] Train loss: 0.045206\n",
      "[Epoch 9/100] valid loss: 0.044717\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6408493236853446\t0.04471723\t0.9622779724843671\t0.9298312547875294\t0.04471722394227982\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_true.txt\n",
      "[Epoch 9/100] test loss: 0.047184\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.6180760782725747\t0.04718372\t0.9601693477473975\t0.9254945855716924\t0.047183720767498015\n",
      "---------------------------\n",
      "Training...\n",
      "Process Training Batch: [489/490][Epoch 10/100] Train loss: 0.043820\n",
      "[Epoch 10/100] valid loss: 0.043634\n",
      "r2/rmse/pearson/spearmanr/val_loss\n",
      "0.646588077407591\t0.04363353\t0.9630161089433229\t0.9305311877395136\t0.043633532524108884\n",
      "Current Best!!\n",
      "Saving in txt...\n",
      "Saved! ../output_step2/30/predictiony_pred.txt\n",
      "Saving in txt...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"functions/extrapolation_transcript.py\", line 546, in <module>\n",
      "    main()\n",
      "  File \"functions/extrapolation_transcript.py\", line 282, in main\n",
      "    save(val_labels, filename=prediction_folder+opt.y_true_output_filename, shuffle=opt.shuffle)\n",
      "  File \"/home/maayanlab/Projects/minji/cycleGAN_gene_expression/scripts/functions/utils.py\", line 105, in save\n",
      "    f1.write(\"\\t\".join(map(str, data[i])))\n",
      "KeyboardInterrupt\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 23804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python functions/extrapolation_transcript.py --input_dataset_name \"ARCHS4_50000_input\" --output_dataset_name \"ARCHS4_50000_output\" --n_epochs 100 --decay_epoch 10 --input_dim 962 --hidden_dim 2048 4096 8192 --output_dim 23614 --num_samples $num_samples --batch_size 100 --exp_index $step2_exp_index --valid_ratio 0.01 --test_ratio 0.01 --y_pred_output_filename \"y_pred.txt\" --y_true_output_filename \"y_true.txt\" --early_stopping --early_stopping_epoch 3 --early_stopping_tol 0.0001 --prediction_folder ../output_step2/$step2_exp_index/prediction\n",
    "# "
   ]
  },
  {
   "source": [
    "## Predicting: Step 0 Preprocessing input file (Optional)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "978 landmark genes in GCTX -> 962 landmark genes in feather format)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n  File \"functions/preprocessing_input_data.py\", line 40, in <module>\n    main()\n  File \"functions/preprocessing_input_data.py\", line 17, in main\n    with open(opt.gene_names, \"r\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: '../data/processed/overlap_landmark_file.txt'\n"
     ]
    }
   ],
   "source": [
    "!python functions/preprocessing_input_data.py --input_filename ../data/LINCS_CFDE/L1000_GSE92742_landmark_only/L1000_GSE92742_1.gctx --output_filename ../data/LINCS_CFDE/L1000_GSE92742_landmark_only_feather/L1000_GSE92742_1.gctx"
   ]
  },
  {
   "source": [
    "## Predicting: Step 1 Running cycleGAN (L1000->RNA-seq)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Input file format: feather\n",
    "Output file format: txt (tab-separated)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "usage: cyclegan_transcript.py [-h] [--epoch_resume EPOCH_RESUME]\n                              [--n_epochs N_EPOCHS]\n                              [--dataset_nameA DATASET_NAMEA]\n                              [--dataset_nameB DATASET_NAMEB]\n                              [--batch_size BATCH_SIZE] [--lr LR] [--b1 B1]\n                              [--b2 B2] [--weight_decay WEIGHT_DECAY]\n                              [--decay_epoch DECAY_EPOCH] [--n_cpu N_CPU]\n                              [--input_dimA INPUT_DIMA]\n                              [--hidden_dimA HIDDEN_DIMA]\n                              [--output_dimA OUTPUT_DIMA]\n                              [--input_dimB INPUT_DIMB]\n                              [--hidden_dimB HIDDEN_DIMB]\n                              [--output_dimB OUTPUT_DIMB]\n                              [--num_samples NUM_SAMPLES]\n                              [--sample_interval SAMPLE_INTERVAL]\n                              [--checkpoint_interval CHECKPOINT_INTERVAL]\n                              [--n_residual_blocks N_RESIDUAL_BLOCKS]\n                              [--lambda_cyc LAMBDA_CYC]\n                              [--lambda_id LAMBDA_ID]\n                              [--load_model_index LOAD_MODEL_INDEX]\n                              [--eval_dataset_nameA EVAL_DATASET_NAMEA]\n                              [--eval_dataset_nameB EVAL_DATASET_NAMEB]\n                              [--exp_index EXP_INDEX] [--ispredicting]\n                              [--cell_line CELL_LINE] [--gamma GAMMA]\n                              [--shuffle] [--evaluation]\n                              [--y_true_output_filename Y_TRUE_OUTPUT_FILENAME]\n                              [--y_pred_output_filename Y_PRED_OUTPUT_FILENAME]\n                              [--prediction_folder PREDICTION_FOLDER]\n                              [--benchmark_evaluation]\ncyclegan_transcript.py: error: argument --exp_index: expected one argument\n"
     ]
    }
   ],
   "source": [
    "!python functions/cyclegan_transcript.py --ispredicting --exp_index $step1_exp_index --load_model_index $step1_model_index --eval_dataset_nameA ../data/Evaluation/GSE92742_Broad_LINCS_Level3_INF_mlr12k_n203x962_celllineMCF7.f --y_pred_output_filename step1.txt --prediction_folder \"../prediction/\" "
   ]
  },
  {
   "source": [
    "## Predicting: Step 2 Extrapolating (962 dim RNA-seq -> 25,312 dim RNA-seq)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n  File \"functions/extrapolation_transcript.py\", line 151, in <module>\n    with open(log_folder+\"args.txt\", \"r\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: '../output_step2/30/logs/args.txt'\n"
     ]
    }
   ],
   "source": [
    "!python functions/extrapolation_transcript.py --ispredicting --exp_index $step2_exp_index --eval_input_dataset_name ../prediction/step1.txt --y_pred_output_filename step2.txt --prediction_folder \"../prediction/\""
   ]
  },
  {
   "source": [
    "## Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading... ../data/Evaluation/ARCHS4_human_matrix_v9_n203x25312_celllineMCF7.f\n",
      "Loading... ../prediction/step2.txt\n",
      "                A1BG      A1CF       A2M  ...       ZYX     ZZEF1      ZZZ3\n",
      "index                                     ...                              \n",
      "GSM1244820  0.499148  0.077632  0.146216  ...  2.026383  1.929692  1.914497\n",
      "GSM1069746  0.624828  0.158088  0.042253  ...  2.001709  2.007102  1.742260\n",
      "GSM942209   0.740817  0.033552  0.184026  ...  1.668504  2.165832  1.819612\n",
      "GSM1244818  0.484494  0.000000  0.043525  ...  2.023462  1.996412  1.838877\n",
      "GSM1244822  0.450148  0.066832  0.130643  ...  2.004296  1.941199  1.883010\n",
      "...              ...       ...       ...  ...       ...       ...       ...\n",
      "GSM3538846  0.847936  0.088696  0.020267  ...  1.614222  2.083172  2.243796\n",
      "GSM4081348  1.266858  0.000000  0.494607  ...  1.999887  1.888118  1.464791\n",
      "GSM4081349  1.009861  0.000000  0.072061  ...  1.798051  1.837976  1.745063\n",
      "GSM4081352  1.119146  0.160137  0.398369  ...  1.831288  1.956366  1.598800\n",
      "GSM4081353  1.283565  0.180914  0.351877  ...  1.869487  1.870719  1.519693\n",
      "\n",
      "[203 rows x 25312 columns]\n",
      "                                              A1BG  ...      ZZZ3\n",
      "DOS052_MCF7_24H_X1_F2B3_DUO52HI53LO:E09   3.903545  ...  7.696340\n",
      "MUC.CP002_MCF7_24H_X3_B7_DUO52HI53LO:A06  1.100226  ...  3.647694\n",
      "HDAC001_MCF7_6H_X3_F1B3_DUO52HI53LO:P23   1.064924  ...  3.657683\n",
      "CPC007_MCF7_6H_X4_F1B5_DUO52HI53LO:K01    1.080487  ...  3.566472\n",
      "DOS054_MCF7_24H_X1_F3B4_DUO52HI53LO:K08   1.270056  ...  2.570651\n",
      "...                                            ...  ...       ...\n",
      "CPC010_MCF7_24H_X1_B5_DUO52HI53LO:P02     1.461900  ...  4.248544\n",
      "CPC020_MCF7_6H_X1_B4_DUO52HI53LO:F05      1.637367  ...  4.549139\n",
      "DOS052_MCF7_24H_X1_F2B3_DUO52HI53LO:B14   1.674390  ...  3.285955\n",
      "CPC019_MCF7_24H_X5_B5_DUO52HI53LO:B17     1.643735  ...  4.425300\n",
      "PCLB001_MCF7_6H_X2_F2B6_DUO52HI53LO:C02   1.174677  ...  3.741060\n",
      "\n",
      "[203 rows x 25312 columns]\n",
      "r2 -902297.4531373981\n",
      "rmse 4.240509740769764\n",
      "pearson 0.76920498078251\n",
      "spearmanr 0.7969418689998798\n"
     ]
    }
   ],
   "source": [
    "!python functions/evaluation.py --y_true ../data/Evaluation/ARCHS4_human_matrix_v9_n203x25312_celllineMCF7.f --y_pred ../prediction/step2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}